{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec9792b",
   "metadata": {},
   "source": [
    "# Загрузка всех моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb48b00",
   "metadata": {},
   "source": [
    "## Эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eea6e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import InfinityEmbeddings\n",
    "\n",
    "emb_model_BERTA = InfinityEmbeddings(model=\"sergeyzh/BERTA\", infinity_api_url=\"http://127.0.0.1:7997\")\n",
    "emb_model_USER2 = InfinityEmbeddings(model=\"deepvk/USER2-base\", infinity_api_url=\"http://127.0.0.1:7997\")\n",
    "emb_model_RU_EN = InfinityEmbeddings(model=\"ai-forever/ru-en-RoSBERTa \", infinity_api_url=\"http://127.0.0.1:7997\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb1312",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a129a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import Optional, Union\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "class SGlangModel(DeepEvalBaseLLM):\n",
    "    def __init__(self, \n",
    "                 model_name: str, \n",
    "                 base_url: str, \n",
    "                 api_key: Optional[str] = \"NET\",\n",
    "                 enable_thinking: bool = False): # Параметр для управления режимом мышления Qwen3\n",
    "        \"\"\"\n",
    "        Инициализирует модель SGlang.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Имя модели.\n",
    "            base_url (str): Базовый URL для API.\n",
    "            api_key (Optional[str]): API ключ. По умолчанию \"NET\".\n",
    "            enable_thinking (bool): Флаг для управления поведением моделей Qwen3.\n",
    "                                     Если True, к промпту для Qwen3 будет добавлен \"/think\" (для стимуляции процесса размышления).\n",
    "                                     Если False, к промпту для Qwen3 будет добавлен \"/no_think\".\n",
    "                                     Вне зависимости от этого флага, блок <think> будет удален из финального вывода\n",
    "                                     для Qwen3 в режиме генерации текста (когда schema is None).\n",
    "                                     По умолчанию False.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "        self.api_key = api_key if api_key is not None else os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.enable_thinking = enable_thinking \n",
    "        self._sync_client: Optional[OpenAI] = None\n",
    "        self._async_client: Optional[AsyncOpenAI] = None\n",
    "\n",
    "    def load_model(self) -> OpenAI:\n",
    "        if self._sync_client is None:\n",
    "            self._sync_client = OpenAI(base_url=self.base_url, api_key=self.api_key)\n",
    "        return self._sync_client\n",
    "\n",
    "    def load_async_model(self) -> AsyncOpenAI:\n",
    "        if self._async_client is None:\n",
    "            self._async_client = AsyncOpenAI(base_url=self.base_url, api_key=self.api_key)\n",
    "        return self._async_client\n",
    "\n",
    "    def _clean_qwen3_output(self, text_response: str) -> str:\n",
    "        \"\"\"\n",
    "        Удаляет начальный блок <think>...</think> из ответов модели Qwen3.\n",
    "        \"\"\"\n",
    "        pattern = r'^\\s*<think>.*?</think>\\s*'\n",
    "        cleaned_response = re.sub(pattern, '', text_response, count=1, flags=re.DOTALL)\n",
    "        return cleaned_response\n",
    "\n",
    "    def generate(self, prompt: str, schema: Optional[BaseModel] = None) -> Union[str, BaseModel]:\n",
    "        \"\"\"\n",
    "        Генерирует ответ от модели. \n",
    "        Для модели 'Qwen3' (без схемы):\n",
    "        - К промпту добавляется \"/think\" или \"/no_think\" в зависимости от self.enable_thinking.\n",
    "        - Блок <think> всегда удаляется из финального ответа.\n",
    "        \"\"\"\n",
    "        client = self.load_model()\n",
    "        \n",
    "        processed_prompt = prompt\n",
    "        # Проверка на Qwen3 (нечувствительная к регистру) и отсутствие схемы\n",
    "        is_qwen3_text_mode = \"qwen3\" in self.model_name.lower() and schema is None\n",
    "\n",
    "        if is_qwen3_text_mode:\n",
    "            # Удаляем существующие теги /think или /no_think из конца промпта\n",
    "            processed_prompt = re.sub(r'\\s*/think\\s*$', '', processed_prompt, flags=re.IGNORECASE).strip()\n",
    "            processed_prompt = re.sub(r'\\s*/no_think\\s*$', '', processed_prompt, flags=re.IGNORECASE).strip()\n",
    "            \n",
    "            if self.enable_thinking:\n",
    "                processed_prompt += \" /think\" # Инструктируем Qwen3 выполнить процесс размышления\n",
    "            else:\n",
    "                processed_prompt += \" /no_think\" # Инструктируем Qwen3 пропустить/минимизировать размышления\n",
    "        \n",
    "        try:\n",
    "            if schema is None:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=self.model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": processed_prompt}], \n",
    "                )\n",
    "                raw_content = response.choices[0].message.content\n",
    "                \n",
    "                if is_qwen3_text_mode:\n",
    "                    # Для Qwen3 в текстовом режиме всегда очищаем вывод от блока <think>.\n",
    "                    # self.enable_thinking контролирует, получает ли модель /think или /no_think в промпте,\n",
    "                    # т.е. будет ли она проходить через процесс размышления.\n",
    "                    return self._clean_qwen3_output(raw_content)\n",
    "                else:\n",
    "                    # Для других моделей возвращаем \"сырой\" контент\n",
    "                    return raw_content\n",
    "            else:\n",
    "                # Режим структурированного вывода с instructor\n",
    "                instructor_client = instructor.from_openai(\n",
    "                    client=client,\n",
    "                    mode=instructor.Mode.JSON \n",
    "                )\n",
    "                response_obj = instructor_client.chat.completions.create(\n",
    "                    model=self.model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "                    response_model=schema, \n",
    "                )\n",
    "                return response_obj\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при синхронной генерации VLLM/Instructor для промпта '{prompt[:50]}...': {e}\")\n",
    "            raise e\n",
    "\n",
    "    async def a_generate(self, prompt: str, schema: Optional[BaseModel] = None) -> Union[str, BaseModel]:\n",
    "        \"\"\"\n",
    "        Асинхронно генерирует ответ от модели.\n",
    "        Для модели 'Qwen3' (без схемы):\n",
    "        - К промпту добавляется \"/think\" или \"/no_think\" в зависимости от self.enable_thinking.\n",
    "        - Блок <think> всегда удаляется из финального ответа.\n",
    "        \"\"\"\n",
    "        client = self.load_async_model()\n",
    "\n",
    "        processed_prompt = prompt\n",
    "        # Проверка на Qwen3 (нечувствительная к регистру) и отсутствие схемы\n",
    "        is_qwen3_text_mode = \"qwen3\" in self.model_name.lower() and schema is None\n",
    "\n",
    "        if is_qwen3_text_mode:\n",
    "            # Удаляем существующие теги /think или /no_think из конца промпта\n",
    "            processed_prompt = re.sub(r'\\s*/think\\s*$', '', processed_prompt, flags=re.IGNORECASE).strip()\n",
    "            processed_prompt = re.sub(r'\\s*/no_think\\s*$', '', processed_prompt, flags=re.IGNORECASE).strip()\n",
    "\n",
    "            if self.enable_thinking:\n",
    "                processed_prompt += \" /think\" # Инструктируем Qwen3 выполнить процесс размышления\n",
    "            else:\n",
    "                processed_prompt += \" /no_think\" # Инструктируем Qwen3 пропустить/минимизировать размышления\n",
    "\n",
    "        try:\n",
    "            if schema is None:\n",
    "                response = await client.chat.completions.create(\n",
    "                    model=self.model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": processed_prompt}], \n",
    "                )\n",
    "                raw_content = response.choices[0].message.content\n",
    "\n",
    "                if is_qwen3_text_mode:\n",
    "                    # Для Qwen3 в текстовом режиме всегда очищаем вывод от блока <think>.\n",
    "                    # self.enable_thinking контролирует, получает ли модель /think или /no_think в промпте.\n",
    "                    return self._clean_qwen3_output(raw_content)\n",
    "                else:\n",
    "                    # Для других моделей возвращаем \"сырой\" контент\n",
    "                    return raw_content\n",
    "            else:\n",
    "                # Режим структурированного вывода с instructor\n",
    "                instructor_client = instructor.from_openai(\n",
    "                    client=client,\n",
    "                    mode=instructor.Mode.JSON\n",
    "                )\n",
    "                response_obj = await instructor_client.chat.completions.create(\n",
    "                    model=self.model_name,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "                    response_model=schema,\n",
    "                )\n",
    "                return response_obj\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при асинхронной генерации VLLM/Instructor для промпта '{prompt[:50]}...': {e}\")\n",
    "            raise e\n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        return self.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505b54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qwen3_8_SGlang = SGlangModel(model_name=\"Qwen/Qwen3-8B\", base_url=\"http://85.143.167.11:30000/v1\")\n",
    "Qwen3_8_SGlang_Reasoning = SGlangModel(model_name=\"Qwen/Qwen3-8B\", base_url=\"http://85.143.167.11:30000/v1\", enable_thinking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3530c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "Cogito = ChatOpenAI(model=\"deepcogito/cogito-v1-preview-llama-8B\", base_url = \"http://85.143.167.11:30000/v1\", api_key=\"NO\")\n",
    "Qwen3_8 = ChatOpenAI(model=\"Qwen/Qwen3-8B\", base_url = \"http://85.143.167.11:30000/v1\", api_key=\"NO\")\n",
    "Gemma = ChatOpenAI(model=\"google/gemma-3-4b-it\", base_url = \"http://85.143.167.11:30000/v1\", api_key=\"NO\")\n",
    "Yandex = ChatOpenAI(model=\"yandex/YandexGPT-5-Lite-8B-instruct\", base_url = \"http://85.143.167.11:30000/v1\", api_key=\"NO\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18618758",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Чанкинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8ebc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_1 = \"/home/lanarich/Рабочий стол/Diploma/data/output_markdown/Anatomia_cheloveka_1_tom_2.md\"\n",
    "file_path_2 = \"/home/lanarich/Рабочий стол/Diploma/data/output_markdown/Kapandzhi_-_Pozvonochnik.md\" \n",
    "file_path_3 = \"/home/lanarich/Рабочий стол/Diploma/data/output_markdown/Kozhnye_i_venericheskie_bolezni_pod_red_O_Yu_Olisovoi_774.md\" \n",
    "file_path_4 = \"/home/lanarich/Рабочий стол/Diploma/data/output_markdown/Molekulyarnaya_biologia_kletki_Tom_1.md\" \n",
    "\n",
    "with open(file_path_1, 'r', encoding='utf-8') as file:\n",
    "    book_1 = file.read()\n",
    "\n",
    "with open(file_path_2, 'r', encoding='utf-8') as file:\n",
    "    book_2 = file.read()\n",
    "\n",
    "with open(file_path_3, 'r', encoding='utf-8') as file:\n",
    "    book_3 = file.read()\n",
    "\n",
    "with open(file_path_4, 'r', encoding='utf-8') as file:\n",
    "    book_4 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666e40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chonkie import TokenChunker\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "chunker_token = TokenChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=128,\n",
    "    return_type= \"texts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c73d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1_token = chunker_token.chunk(book_1)\n",
    "book_2_token = chunker_token.chunk(book_2)\n",
    "book_3_token = chunker_token.chunk(book_3)\n",
    "book_4_token = chunker_token.chunk(book_4)\n",
    "full_books_token = book_1_token + book_2_token + book_3_token + book_4_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b034b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "\n",
    "chunker_rec = RecursiveChunker.from_recipe(\n",
    "        name=\"markdown\",\n",
    "        chunk_size=512,\n",
    "        tokenizer_or_token_counter=tokenizer, \n",
    "        min_characters_per_chunk=75,         \n",
    "        return_type='texts'          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade7ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1_rec = chunker_rec.chunk(book_1)\n",
    "book_2_rec = chunker_rec.chunk(book_2)\n",
    "book_3_rec = chunker_rec.chunk(book_3)\n",
    "book_4_rec = chunker_rec.chunk(book_4)\n",
    "full_books_rec = book_1_rec + book_2_rec + book_3_rec + book_4_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c3bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default prompt name is set to 'Classification'. This prompt will be applied to all `encode()` calls, except if `encode()` is called with `prompt` or `prompt_name` parameters.\n"
     ]
    }
   ],
   "source": [
    "from chonkie import LateChunker\n",
    "chunker_late = LateChunker.from_recipe(\n",
    "        name = \"markdown\",\n",
    "        embedding_model=\"sergeyzh/BERTA\",\n",
    "        chunk_size=512, \n",
    "        min_characters_per_chunk=75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06610d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/lanarich/.cache/pypoetry/virtualenvs/diploma-au9TFMuk-py3.11/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/lanarich/.cache/pypoetry/virtualenvs/diploma-au9TFMuk-py3.11/lib/python3.11/site-packages/numpy/_core/_methods.py:137: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "book_1_late = chunker_late.chunk(book_1)\n",
    "book_2_late = chunker_late.chunk(book_2)\n",
    "book_3_late = chunker_late.chunk(book_3)\n",
    "book_4_late = chunker_late.chunk(book_4)\n",
    "full_books_late = book_1_late + book_2_late + book_3_late + book_4_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb3dccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_books_late_texts = [chunk_object.text for chunk_object in full_books_late]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59106b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99664e0",
   "metadata": {},
   "source": [
    "## БД с разными эмбеддинговыми моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c721a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents_token = [Document(page_content=text) for text in full_books_token]\n",
    "documents_rec = [Document(page_content=text) for text in full_books_rec]\n",
    "documents_late = [Document(page_content=text) for text in full_books_late_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62ff71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_293245/3470624304.py:3: RuntimeWarning: coroutine 'VectorStore.afrom_documents' was never awaited\n",
      "  vectorstore_token = Qdrant.from_documents(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import Qdrant\n",
    "\n",
    "vectorstore_token = Qdrant.from_documents(\n",
    "    documents=documents_token,\n",
    "    embedding=emb_model_BERTA,\n",
    "    collection_name=\"TokenChunker_NAIVE\",\n",
    "    url=\"http://localhost:6333\",\n",
    ")\n",
    "\n",
    "retriever_token = vectorstore_token.as_retriever(search_kwargs={\"k\": 5}) \n",
    "\n",
    "# vectorstore_rec = Qdrant.from_documents(\n",
    "#     documents=documents_rec,\n",
    "#     embedding=emb_model_BERTA,\n",
    "#     collection_name=\"RecursiveChunker_NAIVE\",\n",
    "#     url=\"http://localhost:6333\",\n",
    "# )\n",
    "\n",
    "# retriever_rec = vectorstore_rec.as_retriever(search_kwargs={\"k\": 5}) \n",
    "\n",
    "# vectorstore_rec = Qdrant.from_documents(\n",
    "#     documents=documents_late,\n",
    "#     embedding=emb_model_BERTA,\n",
    "#     collection_name=\"LateChunker_NAIVE\",\n",
    "#     url=\"http://localhost:6333\",\n",
    "# )\n",
    "\n",
    "# retriever_late = vectorstore_rec.as_retriever(search_kwargs={\"k\": 5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "018cbd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'_id': '5475c3b6-17ea-4ab9-a3d5-ad1235284fa2', '_collection_name': 'TokenChunker_NAIVE'}, page_content=\" S 2 2 cd S ч ~ X Л>>- I >, * ё > < ё   | >< « 2 X сг 2 со 05 Л § с                                                    |                                                              |\\n|------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------|-----------------------------------------------------------|------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|--------------------------------------------------------------|\\n| Через отверстия проходят 2 s а> со | cd н X X сх X ю cd «! = 2 X D 0 0                                | * О н о о, с « S м о <D гг х н cd -& * s Й g 5 § a ч g sc s ff) s | м о н о а с « х м о <и £Г X Й •S ' 5 s 2 * 3 a g С а > pa | 05 cd X s <D а 05 05 05 X X D o, H Ж oo                                | < и о X со О X а> со О X о . 05 § X со cd Ю >«-✓ и О X V X X d со О н 1) X о О X о              | о (Н - о X £Г 2 С О 05 t0 3 о X л н (D О 05 cd X cd С О О Ч cd X X < D 00 cd | >> X ' X « ° cd эХ х 2 а £ cd * о о X S СП 05 c d со S 5 э 2 |\\n|                                    | cd н X X а х V O cd 4 05 X а 0 J н С и <                         |                                                                   |                                                           | ■0 C O H D C O 5 * X g 3 5 5 I 2 о i 5 s «. и 05 05 5 * g о cd о го со | щ cd со <> L Я X 5 Q. < L >( D С '                                                              |                                                                              |                                                              |\\n| 09 Н О                             | О X >* 5 « х ч *§ Н к з Я £ § СО С О                             | о а К С a О g, 2 * CO cd a < d >» O, s c &я ё S 2 о < со          | cd X -о Ч cd X cd cd а >» X н Ъ 6 а н <> L X < X £        | D О X S и о.                                                           | < и о X Е\"),\n",
       " Document(metadata={'_id': '80181f84-4f2a-4434-a15e-f4c7c267ebfb', '_collection_name': 'TokenChunker_NAIVE'}, page_content=\" § & р я 03 Я я К а и | ю &я 5 2 1 I s и л о                                                                         | о, о и >» ю « 3 S В 5 4 о з И 6 U                                                              |\\n| ю --------- Я Я Я a * с о О § и Я 0 3 Я Я S' s « ч cj ч я м я о § и я я У н а s                                                                                                                          | я ч я . g § l a 5 - 3 ^ S С s                                                                | я Е Г 5 О Я я й > я а я (D Я я 3 6 S ч ^ О Я с S                                               |\\n\\n| я а 0 я « 3 S Л S 1 а я я 0 3 го                                           | 0 3 о, < и я « 3 S я 4 < и н оз О- я я 0 3 со                                                                                            | я а ( U я >s 2 Я J3 6 < и 1 о. я я я а < D Я « 2 Я я 5 1 Он S я я го                                                                                              |\\n|----------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| S л а S в сх с Я ОS 5 О. Я я 4 ё S * 1 1 § « о 8 iм - о s С s о s          | н < D Я ю s (• - о S Я § 0 Я О я °- а п С * ч > ю                                                                                        | я о (4 - я ч о D - н о а > о. > > 4 О н < и S ю я Й я я с 5 >. О О ю , я К л £ Сю >> 0 o' Он 1 ю н я § : а я _ ^ я С с                                            |\\n| Он < D ю < и a я 4 о ю ►s a н £ § 5 о о Н s > О * 5 « о, о и о а >» о из я | Д я 3S S « о о- Ю я 2 « 5 а о »* и. ^ я 5 о- Юя e t >> S о > - S ю 5 * « S S я * * i S=§ * WL- (< Т л н Я ч Я св S - н я н у о я о Й я м |\"),\n",
       " Document(metadata={'_id': 'c738ae75-1b8f-4087-a40a-99867a8999f1', '_collection_name': 'TokenChunker_NAIVE'}, page_content=\"6 а Cl О § Я л 5 * 1 § р 3 < - 4 W ,2 s Ю я Л о F S о - е X * х С а Б и о я g с « 2 Я 5 о я я 3 a cd ( L) го ю | s v 1 и ч а А cd Я А ЗЯ о с о ч Ч о о vo cd Я я о А ч о н <и V O о S о о ч я К cd Он н о S ( D о >0 с о о М н о с зЯ о О я ч с о X ч о Он я я &> ч о с о 03 <и о го VO я c d                   | о? cd 1 Я о Н 4 О cd о 2 * л * н и 8 * I * О о Й ° Я е « 5 я 2 о S Е ч Он cd о) Г ОV O c d 4 Й w § 5 8. « 2 п 5 « Он Я (U я я g ч § i и s r ^ S Я а 2 2 5 g о ^ я s |\\n| 1 О с о cd я Я Он И а 1н - ч cd 3 S а А ч ч cd а О ч из ч                                                                                    | 1 э 3 S ч cd с о cd я я 5 S 1) ч о и Он cd Н Я                                       |                                                                                                                  | 05 cd X X о 03 rrt § а 5 3 С £                                                                                                                                        |                                                                                                                                                                  | Я а 2 S R cd с о о Я Он и VO                                                                                                                                                                   | о а А * о О 3 я о н о cd я А « Н ч S cd cd Чю я S vo Я А X ч я                                                                                                      |\\n\\n| О 4 оз 5 « 3 ж н о о Я х 6 О со • -I О Г-н « С vo о а о < и Ж > Я 3 оа О 4 л 5 « н о о о < о о                                                                                                                              | Ж^ 64 * 1 1 а * « Ж2 X Я о D - а 3 D ю                                                                 |                                          |\\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|------------------------------------------|\\n| *[ ■ 5 е л 2 5 х Л - ч S' Й С О- О < D н\"),\n",
       " Document(metadata={'_id': '2dd174f5-aec6-48fb-89ec-be587a43799d', '_collection_name': 'TokenChunker_NAIVE'}, page_content=\" » (Н - cd о МО в                        | X <> L a 2 cd П И >> в vo л со н а> 03 « cd Ж I   | 2 5 * >» *                                                                                   | я х\\\\ s . >< « W3 * ' л о Ж ® 5 cd О ^ н о О Ч о Х ^ 3 3 g 5 I с         | « 3 Ж Й Г 3 го 03 Н З §   |                                                                   |\\n|-----------------------------------|----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|--------------------------------------------------|------------------------------------------------|-----------------------------------------------------------------------|--------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|---------------------------|-------------------------------------------------------------------|\\n| а> В* а» S в к I о 2 со о. 2 й    | о м о ж А Щ cd CQ О <> L Ж ж U Н 4> Ч Ж о < D § В Ж о 03 оэ                                              | (D 3 Ж - О ез cd <> L u Ж Ж Ж < D < D Ж Ж 4 < D О U                                        |                                                  |                                                |                                                                       |        |                                                                                       | <> L D Ж * Ж ж cd со Ж К о н ж Он ж <и 3 ж _ ж ® « 2 VO Ж cd Н О ° cd 2 U Qt= j  |                                                   | о? cd Ж S < D О                                                                              | cd * О и о Ж гг 3 со « из 4 о ж л н <> L о 03 cd ж со Ж «; = D c d CQ Ж |                           | О Ж со О Ж < D 03 о ж Он 03 4 ж со cd VO < D g о 5 Ж к оз ! | м Г |\\n| о о U                             | из - н 03 в! cd Ж 1* § О Я 1 Д U Л Я Ч s Я К 2 «и ~ 5 я 3 к к х в 2 X S о в 2 u 03 jj r cd Й * § » R . и | оз cd Ж ►о cd £ * о ж о £ ж ж г ж 5 ё 2 г Ж< Ц 0 5 2 R «К 5 й О ^ U ю                      | 03 cd Ж ^ 0 3 vo S & ю д н 5 К * Ж X             | <и 3 ж ж cd VO cd Он cd vo I О ж ж\"),\n",
       " Document(metadata={'_id': '6e1f5e99-1b08-486b-95f0-2d25c1530dc8', '_collection_name': 'TokenChunker_NAIVE'}, page_content=\" я                                                                                                      |\\n\\n| О 4 оз 5 « 3 ж н о о Я х 6 О со • -I О Г-н « С vo о а о < и Ж > Я 3 оа О 4 л 5 « н о о о < о о                                                                                                                              | Ж^ 64 * 1 1 а * « Ж2 X Я о D - а 3 D ю                                                                 |                                          |\\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|------------------------------------------|\\n| *[ ■ 5 е л 2 5 х Л - ч S' Й С О- О < D н н о c d н < U 0 > С З ( U *2 н Я <L > Ь н ( Я U S g g н о ё ч 1 § С О а * и 3 > > х « и Й °< О. U X с , п о >» ж о 5 2 <> L 0 3 ю я л U                                            | 33 2 3 ж С в о <> L S 5 Н 0 > 2 s s ж                                                                  |                                          |\\n| о я Л К й 4 О, v (D * C« Q О О 5 « Н ( D                                                                                                                                                                                    | о н о 5 s р, н 5 ° >» о мэ а                                                                           |                                          |\\n| Xл I ж Й Ч « » « - Я 5 я S 3 Р 0 н S (1 - е о о 3 s § ю 5 03 . . ч> Я 1 в г о - ло 2 5 а я Э ' и а а Й.й з Е « ч - ®Ю « й ~ 8 * * * 5 3 в « 2 х О ^ ^ Л о а л о н 5 У ' О дз о а о ж Т r Q. О. г О О й > d I -ж | н ю 5 « Ч | cd S л н о о ж х а о g < D Ж оа 3 О Ж ж л 5 05 * е в э Я Ж О - Q о а 4 о 0 3 Ж О О н < L >( D 'О 2 о ч |                                          |\\n| а • Я § Э § 3 S S «5 3 К с в c d Ж® ■ § Ч S                                                                                                                                                                                 | ч Уч' * ^\")]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_token.invoke(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd176c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"[Документ {i+1}]: {doc.page_content}\" for i, doc in enumerate(docs))\n",
    "\n",
    "def clean_qwen3_output(text_response: str) -> str:\n",
    "\n",
    "    pattern = r'^\\s*<think>.*?</think>\\s*'\n",
    "    cleaned_response = re.sub(pattern, '', text_response, count=1, flags=re.DOTALL)\n",
    "    return cleaned_response    \n",
    "  \n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"    \n",
    "Ты — экспертный помощник. Ответь на вопрос, используя только предоставленный контекст. Если ответа нет в контексте, скажи \"Не знаю\".\n",
    "{context}   \n",
    "    \n",
    "Вопрос: {question} /no_think  \n",
    "\"\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37940d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (    \n",
    "    {\"context\": retriever_token | format_docs, \"question\": RunnablePassthrough()}    \n",
    "    # | prompt    \n",
    "    # | Qwen3_8   \n",
    "    # | StrOutputParser()\n",
    "    # | clean_qwen3_output     \n",
    ") \n",
    "\n",
    "# rag_chain = (    \n",
    "#     {\"context\": retriever_rec | format_docs, \"question\": RunnablePassthrough()}    \n",
    "#     | prompt    \n",
    "#     | Qwen3_8   \n",
    "#     | StrOutputParser()\n",
    "#     | clean_qwen3_output     \n",
    "# ) \n",
    "\n",
    "# rag_chain = (    \n",
    "#     {\"context\": retriever_late | format_docs, \"question\": RunnablePassthrough()}    \n",
    "#     | prompt    \n",
    "#     | Qwen3_8   \n",
    "#     | StrOutputParser()\n",
    "#     | clean_qwen3_output     \n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94292a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"Когда и какие добавочные центры окостенения образуются в эпифизах трубчатых костей, и как они влияют на формирование отростков, бугров и гребней?\")    \n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma-au9TFMuk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
